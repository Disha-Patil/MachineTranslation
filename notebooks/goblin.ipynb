{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../Scripts')\n",
    "import pandas as pd\n",
    "from multilingualtranslation import MultiLangTranslation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_or_path =\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\"\n",
    "model_file =\"Meta-Llama-3.1-8B-Instruct-Q6_K.gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first n_ctx is set to 512\n",
      "error in loading model from huggingface\n",
      "(MaxRetryError('HTTPSConnectionPool(host=\\'huggingface.co\\', port=443): Max retries exceeded with url: /api/models/lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000176AA1A6A50>: Failed to resolve \\'huggingface.co\\' ([Errno 11001] getaddrinfo failed)\"))'), '(Request ID: ace124bf-5b64-498b-a2a4-ba7fd420bc93)')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MultiLangTranslation' object has no attribute 'llm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ko2en\u001b[38;5;241m=\u001b[39m\u001b[43mMultiLangTranslation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkorean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43menglish\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mn_ctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43mnlp_obj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# default nlp obj is korean\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\Disha\\PROJECTS\\MachineTranslation\\notebooks\\../Scripts\\multilingualtranslation.py:49\u001b[0m, in \u001b[0;36mMultiLangTranslation.__init__\u001b[1;34m(self, source_lang, target_lang, model_name_or_path, model_file, n_ctx, nlp_obj)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in loading model from huggingface\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(err)\n\u001b[1;32m---> 49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_ctx is set to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241m.\u001b[39mn_ctx()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultiLangTranslation' object has no attribute 'llm'"
     ]
    }
   ],
   "source": [
    "ko2en=MultiLangTranslation('korean', 'english', \n",
    "                     model_name_or_path,model_file, \n",
    "                     n_ctx=None,nlp_obj=None) # default nlp obj is korean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>src_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>숱한 전장에서 수천의 피를 묻힌 검이 제 주인의 피까지 묻혔으니 오죽 했을까?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>오직 도깨비 신부만이 그 검을 뽑을 것이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>검을 뽑으면 무(아무것도 아닌 것;Nothing/Zero)로 돌아가 평안 하리라.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>고약한 신탁이 아닐 수 없었지.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 episode                                           src_sent\n",
       "0  도깨비 Episode_1.docx  Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼이...\n",
       "1  도깨비 Episode_1.docx        숱한 전장에서 수천의 피를 묻힌 검이 제 주인의 피까지 묻혔으니 오죽 했을까?\n",
       "2  도깨비 Episode_1.docx                           오직 도깨비 신부만이 그 검을 뽑을 것이다.\n",
       "3  도깨비 Episode_1.docx      검을 뽑으면 무(아무것도 아닌 것;Nothing/Zero)로 돌아가 평안 하리라.\n",
       "4  도깨비 Episode_1.docx                                  고약한 신탁이 아닐 수 없었지."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goblin_data=ko2en.readText(\"../data/도깨비 dialogs/\")\n",
    "\n",
    "goblin_df=pd.DataFrame(goblin_data.items(),columns=['episode','text'])\n",
    "goblin_df['src_sent']=goblin_df['text'].apply(lambda txt: ko2en.get_sentences(txt))\n",
    "goblin_df=goblin_df.explode('src_sent')\n",
    "\n",
    "goblin_df=goblin_df.drop(columns=['text'],axis=1).reset_index(drop=True)\n",
    "goblin_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    18 runs   (    0.25 ms per token,  3954.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5476.12 ms /    34 tokens (  161.06 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:        eval time =    6960.17 ms /    17 runs   (  409.42 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =   12476.96 ms /    51 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     8 runs   (    0.26 ms per token,  3835.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2205.44 ms /    14 tokens (  157.53 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:        eval time =    3122.37 ms /     7 runs   (  446.05 ms per token,     2.24 tokens per second)\n",
      "llama_print_timings:       total time =    5346.16 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     8 runs   (    0.31 ms per token,  3212.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2752.51 ms /    15 tokens (  183.50 ms per token,     5.45 tokens per second)\n",
      "llama_print_timings:        eval time =    3214.13 ms /     7 runs   (  459.16 ms per token,     2.18 tokens per second)\n",
      "llama_print_timings:       total time =    5989.94 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /    10 runs   (    0.27 ms per token,  3749.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3249.48 ms /    18 tokens (  180.53 ms per token,     5.54 tokens per second)\n",
      "llama_print_timings:        eval time =    4248.28 ms /     9 runs   (  472.03 ms per token,     2.12 tokens per second)\n",
      "llama_print_timings:       total time =    7522.76 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     5 runs   (    0.28 ms per token,  3604.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2315.79 ms /    10 tokens (  231.58 ms per token,     4.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1792.40 ms /     4 runs   (  448.10 ms per token,     2.23 tokens per second)\n",
      "llama_print_timings:       total time =    4121.19 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     9 runs   (    0.31 ms per token,  3276.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2746.66 ms /    16 tokens (  171.67 ms per token,     5.83 tokens per second)\n",
      "llama_print_timings:        eval time =    3840.87 ms /     8 runs   (  480.11 ms per token,     2.08 tokens per second)\n",
      "llama_print_timings:       total time =    6609.87 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     6 runs   (    0.28 ms per token,  3512.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1992.61 ms /    10 tokens (  199.26 ms per token,     5.02 tokens per second)\n",
      "llama_print_timings:        eval time =    2366.69 ms /     5 runs   (  473.34 ms per token,     2.11 tokens per second)\n",
      "llama_print_timings:       total time =    4378.59 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     5 runs   (    0.26 ms per token,  3894.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2161.79 ms /    12 tokens (  180.15 ms per token,     5.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1785.48 ms /     4 runs   (  446.37 ms per token,     2.24 tokens per second)\n",
      "llama_print_timings:       total time =    3958.97 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    12 runs   (    0.29 ms per token,  3422.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3948.62 ms /    19 tokens (  207.82 ms per token,     4.81 tokens per second)\n",
      "llama_print_timings:        eval time =    5377.22 ms /    11 runs   (  488.84 ms per token,     2.05 tokens per second)\n",
      "llama_print_timings:       total time =    9355.38 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    12 runs   (    0.23 ms per token,  4273.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3539.48 ms /    23 tokens (  153.89 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =    4385.86 ms /    11 runs   (  398.71 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    7951.10 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     2 runs   (    0.36 ms per token,  2762.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1845.04 ms /    12 tokens (  153.75 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =     452.23 ms /     1 runs   (  452.23 ms per token,     2.21 tokens per second)\n",
      "llama_print_timings:       total time =    2303.58 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    10 runs   (    0.29 ms per token,  3489.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4305.86 ms /    28 tokens (  153.78 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =    3928.14 ms /     9 runs   (  436.46 ms per token,     2.29 tokens per second)\n",
      "llama_print_timings:       total time =    8257.05 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /     5 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.29 ms /    12 tokens (  158.52 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1742.69 ms /     4 runs   (  435.67 ms per token,     2.30 tokens per second)\n",
      "llama_print_timings:       total time =    3656.71 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     9 runs   (    0.23 ms per token,  4407.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2783.98 ms /    16 tokens (  174.00 ms per token,     5.75 tokens per second)\n",
      "llama_print_timings:        eval time =    3398.36 ms /     8 runs   (  424.80 ms per token,     2.35 tokens per second)\n",
      "llama_print_timings:       total time =    6199.97 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /    10 runs   (    0.28 ms per token,  3594.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3931.52 ms /    19 tokens (  206.92 ms per token,     4.83 tokens per second)\n",
      "llama_print_timings:        eval time =    4147.33 ms /     9 runs   (  460.81 ms per token,     2.17 tokens per second)\n",
      "llama_print_timings:       total time =    8106.43 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    15 runs   (    0.29 ms per token,  3461.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3328.43 ms /    18 tokens (  184.91 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:        eval time =    7063.72 ms /    14 runs   (  504.55 ms per token,     1.98 tokens per second)\n",
      "llama_print_timings:       total time =   10431.55 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     9 runs   (    0.25 ms per token,  3989.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2020.74 ms /    12 tokens (  168.39 ms per token,     5.94 tokens per second)\n",
      "llama_print_timings:        eval time =    3273.02 ms /     8 runs   (  409.13 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =    5313.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     9 runs   (    0.24 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2163.70 ms /    14 tokens (  154.55 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:        eval time =    3470.97 ms /     8 runs   (  433.87 ms per token,     2.30 tokens per second)\n",
      "llama_print_timings:       total time =    5655.20 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    15 runs   (    0.28 ms per token,  3578.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3134.34 ms /    18 tokens (  174.13 ms per token,     5.74 tokens per second)\n",
      "llama_print_timings:        eval time =    5577.65 ms /    14 runs   (  398.40 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    8747.46 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    15 runs   (    0.26 ms per token,  3858.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3698.68 ms /    23 tokens (  160.81 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:        eval time =    5738.49 ms /    14 runs   (  409.89 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =    9471.42 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /     9 runs   (    0.26 ms per token,  3791.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2503.03 ms /    15 tokens (  166.87 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:        eval time =    3281.90 ms /     8 runs   (  410.24 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =    5805.64 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4710.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2175.68 ms /    14 tokens (  155.41 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2373.82 ms /     6 runs   (  395.64 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    4563.31 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     5 runs   (    0.26 ms per token,  3790.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1854.26 ms /    12 tokens (  154.52 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1624.04 ms /     4 runs   (  406.01 ms per token,     2.46 tokens per second)\n",
      "llama_print_timings:       total time =    3491.12 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     7 runs   (    0.29 ms per token,  3498.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1959.88 ms /    13 tokens (  150.76 ms per token,     6.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2482.69 ms /     6 runs   (  413.78 ms per token,     2.42 tokens per second)\n",
      "llama_print_timings:       total time =    4458.61 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /    13 runs   (    0.24 ms per token,  4132.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2880.45 ms /    18 tokens (  160.02 ms per token,     6.25 tokens per second)\n",
      "llama_print_timings:        eval time =    5048.84 ms /    12 runs   (  420.74 ms per token,     2.38 tokens per second)\n",
      "llama_print_timings:       total time =    7957.89 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /    12 runs   (    0.27 ms per token,  3637.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3118.98 ms /    18 tokens (  173.28 ms per token,     5.77 tokens per second)\n",
      "llama_print_timings:        eval time =    5033.87 ms /    11 runs   (  457.62 ms per token,     2.19 tokens per second)\n",
      "llama_print_timings:       total time =    8183.81 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    14 runs   (    0.38 ms per token,  2609.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4255.91 ms /    21 tokens (  202.66 ms per token,     4.93 tokens per second)\n",
      "llama_print_timings:        eval time =    6727.40 ms /    13 runs   (  517.49 ms per token,     1.93 tokens per second)\n",
      "llama_print_timings:       total time =   11034.09 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /     7 runs   (    0.28 ms per token,  3547.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3117.24 ms /    13 tokens (  239.79 ms per token,     4.17 tokens per second)\n",
      "llama_print_timings:        eval time =    3366.05 ms /     6 runs   (  561.01 ms per token,     1.78 tokens per second)\n",
      "llama_print_timings:       total time =    6512.08 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =      20.11 ms /    75 runs   (    0.27 ms per token,  3728.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =   14154.76 ms /    88 tokens (  160.85 ms per token,     6.22 tokens per second)\n",
      "llama_print_timings:        eval time =   31850.40 ms /    74 runs   (  430.41 ms per token,     2.32 tokens per second)\n",
      "llama_print_timings:       total time =   46192.12 ms /   162 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    10 runs   (    0.27 ms per token,  3668.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2696.37 ms /    13 tokens (  207.41 ms per token,     4.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4002.90 ms /     9 runs   (  444.77 ms per token,     2.25 tokens per second)\n",
      "llama_print_timings:       total time =    6728.37 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     6 runs   (    0.29 ms per token,  3458.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1862.04 ms /    10 tokens (  186.20 ms per token,     5.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2127.75 ms /     5 runs   (  425.55 ms per token,     2.35 tokens per second)\n",
      "llama_print_timings:       total time =    4004.54 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     8 runs   (    0.28 ms per token,  3585.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2795.18 ms /    14 tokens (  199.66 ms per token,     5.01 tokens per second)\n",
      "llama_print_timings:        eval time =    3122.98 ms /     7 runs   (  446.14 ms per token,     2.24 tokens per second)\n",
      "llama_print_timings:       total time =    5938.78 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     9 runs   (    0.22 ms per token,  4502.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2623.66 ms /    16 tokens (  163.98 ms per token,     6.10 tokens per second)\n",
      "llama_print_timings:        eval time =    3450.10 ms /     8 runs   (  431.26 ms per token,     2.32 tokens per second)\n",
      "llama_print_timings:       total time =    6092.96 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     6 runs   (    0.34 ms per token,  2901.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2407.11 ms /    13 tokens (  185.16 ms per token,     5.40 tokens per second)\n",
      "llama_print_timings:        eval time =    2296.25 ms /     5 runs   (  459.25 ms per token,     2.18 tokens per second)\n",
      "llama_print_timings:       total time =    4719.46 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     7 runs   (    0.28 ms per token,  3617.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1668.41 ms /    10 tokens (  166.84 ms per token,     5.99 tokens per second)\n",
      "llama_print_timings:        eval time =    2874.52 ms /     6 runs   (  479.09 ms per token,     2.09 tokens per second)\n",
      "llama_print_timings:       total time =    4559.44 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     6 runs   (    0.23 ms per token,  4382.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2473.26 ms /    15 tokens (  164.88 ms per token,     6.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2168.05 ms /     5 runs   (  433.61 ms per token,     2.31 tokens per second)\n",
      "llama_print_timings:       total time =    4656.25 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /     6 runs   (    0.26 ms per token,  3891.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1997.39 ms /    12 tokens (  166.45 ms per token,     6.01 tokens per second)\n",
      "llama_print_timings:        eval time =    2080.17 ms /     5 runs   (  416.03 ms per token,     2.40 tokens per second)\n",
      "llama_print_timings:       total time =    4090.66 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     3 runs   (    0.31 ms per token,  3264.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1479.17 ms /     8 tokens (  184.90 ms per token,     5.41 tokens per second)\n",
      "llama_print_timings:        eval time =     886.49 ms /     2 runs   (  443.24 ms per token,     2.26 tokens per second)\n",
      "llama_print_timings:       total time =    2376.28 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     3 runs   (    0.28 ms per token,  3521.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.76 ms /     8 tokens (  187.35 ms per token,     5.34 tokens per second)\n",
      "llama_print_timings:        eval time =     982.67 ms /     2 runs   (  491.33 ms per token,     2.04 tokens per second)\n",
      "llama_print_timings:       total time =    2490.90 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /    10 runs   (    0.23 ms per token,  4293.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3364.03 ms /    19 tokens (  177.05 ms per token,     5.65 tokens per second)\n",
      "llama_print_timings:        eval time =    4000.50 ms /     9 runs   (  444.50 ms per token,     2.25 tokens per second)\n",
      "llama_print_timings:       total time =    7386.93 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     5 runs   (    0.18 ms per token,  5512.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1811.94 ms /    10 tokens (  181.19 ms per token,     5.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1789.33 ms /     4 runs   (  447.33 ms per token,     2.24 tokens per second)\n",
      "llama_print_timings:       total time =    3611.63 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    22 runs   (    0.31 ms per token,  3195.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6227.32 ms /    35 tokens (  177.92 ms per token,     5.62 tokens per second)\n",
      "llama_print_timings:        eval time =    9990.60 ms /    21 runs   (  475.74 ms per token,     2.10 tokens per second)\n",
      "llama_print_timings:       total time =   16277.24 ms /    56 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    11 runs   (    0.26 ms per token,  3866.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3708.83 ms /    20 tokens (  185.44 ms per token,     5.39 tokens per second)\n",
      "llama_print_timings:        eval time =    5218.95 ms /    10 runs   (  521.90 ms per token,     1.92 tokens per second)\n",
      "llama_print_timings:       total time =    8956.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    18 runs   (    0.24 ms per token,  4082.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5075.67 ms /    27 tokens (  187.99 ms per token,     5.32 tokens per second)\n",
      "llama_print_timings:        eval time =    8075.39 ms /    17 runs   (  475.02 ms per token,     2.11 tokens per second)\n",
      "llama_print_timings:       total time =   13198.18 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4685.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3691.91 ms /    15 tokens (  246.13 ms per token,     4.06 tokens per second)\n",
      "llama_print_timings:        eval time =    2868.31 ms /     6 runs   (  478.05 ms per token,     2.09 tokens per second)\n",
      "llama_print_timings:       total time =    6580.24 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     7 runs   (    0.29 ms per token,  3482.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2951.82 ms /    16 tokens (  184.49 ms per token,     5.42 tokens per second)\n",
      "llama_print_timings:        eval time =    2481.77 ms /     6 runs   (  413.63 ms per token,     2.42 tokens per second)\n",
      "llama_print_timings:       total time =    5452.07 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    14 runs   (    0.23 ms per token,  4349.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3779.24 ms /    25 tokens (  151.17 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:        eval time =    5146.94 ms /    13 runs   (  395.92 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    8954.67 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    12 runs   (    0.29 ms per token,  3420.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2555.92 ms /    16 tokens (  159.75 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4361.77 ms /    11 runs   (  396.52 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    6945.08 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     8 runs   (    0.25 ms per token,  3980.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2667.92 ms /    17 tokens (  156.94 ms per token,     6.37 tokens per second)\n",
      "llama_print_timings:        eval time =    2828.36 ms /     7 runs   (  404.05 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =    5513.51 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     5 runs   (    0.25 ms per token,  4065.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.63 ms /     9 tokens (  159.40 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1618.41 ms /     4 runs   (  404.60 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =    3063.36 ms /    13 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     5 runs   (    0.23 ms per token,  4370.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1566.75 ms /    10 tokens (  156.68 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1618.27 ms /     4 runs   (  404.57 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =    3197.64 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    24 runs   (    0.19 ms per token,  5279.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3890.03 ms /    25 tokens (  155.60 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    9230.04 ms /    23 runs   (  401.31 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:       total time =   13165.14 ms /    48 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     5 runs   (    0.23 ms per token,  4299.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2278.33 ms /    15 tokens (  151.89 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1623.40 ms /     4 runs   (  405.85 ms per token,     2.46 tokens per second)\n",
      "llama_print_timings:       total time =    3913.45 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     7 runs   (    0.25 ms per token,  4079.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3191.03 ms /    21 tokens (  151.95 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:        eval time =    2390.70 ms /     6 runs   (  398.45 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    5598.66 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    19 runs   (    0.20 ms per token,  5057.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4495.49 ms /    29 tokens (  155.02 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:        eval time =    7174.31 ms /    18 runs   (  398.57 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =   11707.51 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /     8 runs   (    0.24 ms per token,  4104.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1857.59 ms /    12 tokens (  154.80 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:        eval time =    2831.15 ms /     7 runs   (  404.45 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =    4706.12 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    14 runs   (    0.29 ms per token,  3421.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3411.37 ms /    22 tokens (  155.06 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5247.91 ms /    13 runs   (  403.69 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =    8693.63 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     7 runs   (    0.19 ms per token,  5181.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1602.03 ms /    10 tokens (  160.20 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2368.54 ms /     6 runs   (  394.76 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    3983.95 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /     6 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2288.38 ms /    15 tokens (  152.56 ms per token,     6.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1995.03 ms /     5 runs   (  399.01 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    4295.42 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    13 runs   (    0.22 ms per token,  4470.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2801.61 ms /    18 tokens (  155.64 ms per token,     6.42 tokens per second)\n",
      "llama_print_timings:        eval time =    4757.56 ms /    12 runs   (  396.46 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    7586.77 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /    12 runs   (    0.28 ms per token,  3609.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3196.93 ms /    20 tokens (  159.85 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:        eval time =    4331.20 ms /    11 runs   (  393.75 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =    7554.08 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     7 runs   (    0.24 ms per token,  4239.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2264.33 ms /    14 tokens (  161.74 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:        eval time =    2371.03 ms /     6 runs   (  395.17 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    4650.52 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     8 runs   (    0.25 ms per token,  4024.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2000.09 ms /    13 tokens (  153.85 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =    2766.65 ms /     7 runs   (  395.24 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    4784.63 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     8 runs   (    0.28 ms per token,  3595.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1998.07 ms /    13 tokens (  153.70 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:        eval time =    2776.39 ms /     7 runs   (  396.63 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    4793.94 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     5 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1784.26 ms /    11 tokens (  162.21 ms per token,     6.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1579.43 ms /     4 runs   (  394.86 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    3374.46 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     3 runs   (    0.25 ms per token,  3952.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1108.18 ms /     7 tokens (  158.31 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:        eval time =     782.56 ms /     2 runs   (  391.28 ms per token,     2.56 tokens per second)\n",
      "llama_print_timings:       total time =    1898.23 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     7 runs   (    0.30 ms per token,  3322.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1990.45 ms /    13 tokens (  153.11 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2338.57 ms /     6 runs   (  389.76 ms per token,     2.57 tokens per second)\n",
      "llama_print_timings:       total time =    4346.63 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     8 runs   (    0.30 ms per token,  3361.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1841.39 ms /    12 tokens (  153.45 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2740.69 ms /     7 runs   (  391.53 ms per token,     2.55 tokens per second)\n",
      "llama_print_timings:       total time =    4601.61 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     3 runs   (    0.25 ms per token,  4021.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1104.44 ms /     7 tokens (  157.78 ms per token,     6.34 tokens per second)\n",
      "llama_print_timings:        eval time =     792.79 ms /     2 runs   (  396.40 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    1903.61 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    24 runs   (    0.24 ms per token,  4254.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3217.87 ms /    21 tokens (  153.23 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:        eval time =    9009.87 ms /    23 runs   (  391.73 ms per token,     2.55 tokens per second)\n",
      "llama_print_timings:       total time =   12281.73 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    11 runs   (    0.26 ms per token,  3843.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3083.10 ms /    20 tokens (  154.16 ms per token,     6.49 tokens per second)\n",
      "llama_print_timings:        eval time =    3996.82 ms /    10 runs   (  399.68 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    7104.86 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    17 runs   (    0.22 ms per token,  4556.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4123.22 ms /    26 tokens (  158.59 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:        eval time =    6522.48 ms /    16 runs   (  407.65 ms per token,     2.45 tokens per second)\n",
      "llama_print_timings:       total time =   10685.60 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    11 runs   (    0.24 ms per token,  4168.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3132.92 ms /    20 tokens (  156.65 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:        eval time =    3991.66 ms /    10 runs   (  399.17 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    7149.10 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    27 runs   (    0.22 ms per token,  4470.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5169.01 ms /    33 tokens (  156.64 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:        eval time =   10476.99 ms /    26 runs   (  402.96 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =   15700.98 ms /    59 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    20 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5226.61 ms /    34 tokens (  153.72 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:        eval time =    7734.90 ms /    19 runs   (  407.10 ms per token,     2.46 tokens per second)\n",
      "llama_print_timings:       total time =   13001.61 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /     8 runs   (    0.19 ms per token,  5270.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2411.01 ms /    16 tokens (  150.69 ms per token,     6.64 tokens per second)\n",
      "llama_print_timings:        eval time =    2824.84 ms /     7 runs   (  403.55 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =    5250.79 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    12 runs   (    0.32 ms per token,  3098.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2689.01 ms /    17 tokens (  158.18 ms per token,     6.32 tokens per second)\n",
      "llama_print_timings:        eval time =    4361.47 ms /    11 runs   (  396.50 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    7081.05 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     4 runs   (    0.35 ms per token,  2863.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2088.05 ms /    14 tokens (  149.15 ms per token,     6.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.78 ms /     3 runs   (  401.59 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:       total time =    3304.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     8 runs   (    0.27 ms per token,  3743.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2146.51 ms /    14 tokens (  153.32 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:        eval time =    2779.48 ms /     7 runs   (  397.07 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    4944.96 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /     7 runs   (    0.26 ms per token,  3886.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2295.55 ms /    15 tokens (  153.04 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:        eval time =    2380.19 ms /     6 runs   (  396.70 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    4693.97 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     3 runs   (    0.22 ms per token,  4622.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1276.28 ms /     8 tokens (  159.54 ms per token,     6.27 tokens per second)\n",
      "llama_print_timings:        eval time =     800.41 ms /     2 runs   (  400.20 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    2084.10 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     5 runs   (    0.31 ms per token,  3267.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.22 ms /     8 tokens (  169.78 ms per token,     5.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1655.52 ms /     4 runs   (  413.88 ms per token,     2.42 tokens per second)\n",
      "llama_print_timings:       total time =    3027.32 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     3 runs   (    0.28 ms per token,  3567.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1076.29 ms /     7 tokens (  153.76 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =     834.50 ms /     2 runs   (  417.25 ms per token,     2.40 tokens per second)\n",
      "llama_print_timings:       total time =    1918.40 ms /     9 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     6 runs   (    0.35 ms per token,  2844.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1707.27 ms /    11 tokens (  155.21 ms per token,     6.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1984.51 ms /     5 runs   (  396.90 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    3707.27 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    21 runs   (    0.20 ms per token,  5045.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4144.20 ms /    27 tokens (  153.49 ms per token,     6.52 tokens per second)\n",
      "llama_print_timings:        eval time =    8068.43 ms /    20 runs   (  403.42 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =   12253.95 ms /    47 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     9 runs   (    0.29 ms per token,  3465.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2483.36 ms /    16 tokens (  155.21 ms per token,     6.44 tokens per second)\n",
      "llama_print_timings:        eval time =    3368.28 ms /     8 runs   (  421.03 ms per token,     2.38 tokens per second)\n",
      "llama_print_timings:       total time =    5873.92 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    22 runs   (    0.25 ms per token,  3927.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    5673.32 ms /    36 tokens (  157.59 ms per token,     6.35 tokens per second)\n",
      "llama_print_timings:        eval time =    8657.42 ms /    21 runs   (  412.26 ms per token,     2.43 tokens per second)\n",
      "llama_print_timings:       total time =   14380.64 ms /    57 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     9 runs   (    0.27 ms per token,  3699.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2906.19 ms /    18 tokens (  161.46 ms per token,     6.19 tokens per second)\n",
      "llama_print_timings:        eval time =    3164.38 ms /     8 runs   (  395.55 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    6090.05 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /    11 runs   (    0.27 ms per token,  3717.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3142.46 ms /    20 tokens (  157.12 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:        eval time =    3998.62 ms /    10 runs   (  399.86 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    7168.51 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     9 runs   (    0.19 ms per token,  5175.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2099.15 ms /    14 tokens (  149.94 ms per token,     6.67 tokens per second)\n",
      "llama_print_timings:        eval time =    3153.01 ms /     8 runs   (  394.13 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =    5269.33 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     6 runs   (    0.30 ms per token,  3376.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.06 ms /     9 tokens (  158.01 ms per token,     6.33 tokens per second)\n",
      "llama_print_timings:        eval time =    2008.93 ms /     5 runs   (  401.79 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:       total time =    3446.27 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     7 runs   (    0.25 ms per token,  4067.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.76 ms /    11 tokens (  149.16 ms per token,     6.70 tokens per second)\n",
      "llama_print_timings:        eval time =    2383.91 ms /     6 runs   (  397.32 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    4040.58 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /    13 runs   (    0.17 ms per token,  5790.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3112.12 ms /    20 tokens (  155.61 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    4710.25 ms /    12 runs   (  392.52 ms per token,     2.55 tokens per second)\n",
      "llama_print_timings:       total time =    7846.68 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     5 runs   (    0.21 ms per token,  4803.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2001.01 ms /    13 tokens (  153.92 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1592.58 ms /     4 runs   (  398.15 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    3604.93 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    12 runs   (    0.22 ms per token,  4475.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3460.78 ms /    22 tokens (  157.31 ms per token,     6.36 tokens per second)\n",
      "llama_print_timings:        eval time =    4344.83 ms /    11 runs   (  394.98 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    7829.09 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     7 runs   (    0.24 ms per token,  4105.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.04 ms /    10 tokens (  155.60 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2352.53 ms /     6 runs   (  392.09 ms per token,     2.55 tokens per second)\n",
      "llama_print_timings:       total time =    3924.63 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     8 runs   (    0.26 ms per token,  3887.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1756.58 ms /    11 tokens (  159.69 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2712.71 ms /     7 runs   (  387.53 ms per token,     2.58 tokens per second)\n",
      "llama_print_timings:       total time =    4486.90 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    14 runs   (    0.28 ms per token,  3614.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3394.24 ms /    22 tokens (  154.28 ms per token,     6.48 tokens per second)\n",
      "llama_print_timings:        eval time =    5167.74 ms /    13 runs   (  397.52 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    8593.40 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     5 runs   (    0.31 ms per token,  3217.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2010.66 ms /    13 tokens (  154.67 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1600.27 ms /     4 runs   (  400.07 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    3623.79 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     3 runs   (    0.28 ms per token,  3584.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.25 ms /     9 tokens (  158.69 ms per token,     6.30 tokens per second)\n",
      "llama_print_timings:        eval time =     802.05 ms /     2 runs   (  401.02 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:       total time =    2237.15 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     5 runs   (    0.34 ms per token,  2936.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1118.16 ms /     7 tokens (  159.74 ms per token,     6.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.92 ms /     4 runs   (  400.48 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    2734.36 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     4 runs   (    0.22 ms per token,  4613.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1112.81 ms /     7 tokens (  158.97 ms per token,     6.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1198.25 ms /     3 runs   (  399.42 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    2319.08 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     8 runs   (    0.27 ms per token,  3690.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.08 ms /    10 tokens (  162.41 ms per token,     6.16 tokens per second)\n",
      "llama_print_timings:        eval time =    2774.69 ms /     7 runs   (  396.38 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    4417.75 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     9 runs   (    0.20 ms per token,  5119.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1865.11 ms /    12 tokens (  155.43 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    3222.67 ms /     8 runs   (  402.83 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =    5105.22 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     7 runs   (    0.27 ms per token,  3663.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1930.43 ms /    13 tokens (  148.49 ms per token,     6.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2435.71 ms /     6 runs   (  405.95 ms per token,     2.46 tokens per second)\n",
      "llama_print_timings:       total time =    4383.48 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     3 runs   (    0.29 ms per token,  3448.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.07 ms /     8 tokens (  151.76 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:        eval time =     808.22 ms /     2 runs   (  404.11 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =    2030.32 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     9 runs   (    0.25 ms per token,  3954.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2304.00 ms /    15 tokens (  153.60 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:        eval time =    3195.86 ms /     8 runs   (  399.48 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    5519.92 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    10 runs   (    0.21 ms per token,  4866.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2161.83 ms /    14 tokens (  154.42 ms per token,     6.48 tokens per second)\n",
      "llama_print_timings:        eval time =    3588.21 ms /     9 runs   (  398.69 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    5769.73 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /    20 runs   (    0.25 ms per token,  3940.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3847.23 ms /    25 tokens (  153.89 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =    7609.67 ms /    19 runs   (  400.51 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =   11500.29 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     3 runs   (    0.32 ms per token,  3151.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.35 ms /     9 tokens (  155.59 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =     913.53 ms /     2 runs   (  456.76 ms per token,     2.19 tokens per second)\n",
      "llama_print_timings:       total time =    2321.58 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4415.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1966.67 ms /    13 tokens (  151.28 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2793.51 ms /     7 runs   (  399.07 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    4778.36 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     5 runs   (    0.29 ms per token,  3498.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1857.20 ms /    12 tokens (  154.77 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1617.30 ms /     4 runs   (  404.32 ms per token,     2.47 tokens per second)\n",
      "llama_print_timings:       total time =    3485.91 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /    13 runs   (    0.26 ms per token,  3859.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2605.22 ms /    17 tokens (  153.25 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:        eval time =    4767.10 ms /    12 runs   (  397.26 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    7402.86 ms /    29 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.12 ms /    20 runs   (    0.26 ms per token,  3903.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4166.23 ms /    26 tokens (  160.24 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:        eval time =    7518.51 ms /    19 runs   (  395.71 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =   11727.23 ms /    45 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /     5 runs   (    0.27 ms per token,  3756.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.31 ms /     8 tokens (  172.66 ms per token,     5.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1571.79 ms /     4 runs   (  392.95 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =    2965.33 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    14 runs   (    0.26 ms per token,  3902.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3209.66 ms /    20 tokens (  160.48 ms per token,     6.23 tokens per second)\n",
      "llama_print_timings:        eval time =    5120.59 ms /    13 runs   (  393.89 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =    8359.84 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     4 runs   (    0.28 ms per token,  3619.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1884.62 ms /    11 tokens (  171.33 ms per token,     5.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.00 ms /     3 runs   (  400.33 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    3096.69 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /    10 runs   (    0.33 ms per token,  3050.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3188.72 ms /    21 tokens (  151.84 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3563.48 ms /     9 runs   (  395.94 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    6779.43 ms /    30 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    16 runs   (    0.17 ms per token,  5839.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3255.86 ms /    21 tokens (  155.04 ms per token,     6.45 tokens per second)\n",
      "llama_print_timings:        eval time =    5920.56 ms /    15 runs   (  394.70 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    9208.77 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     5 runs   (    0.29 ms per token,  3496.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2013.60 ms /    13 tokens (  154.89 ms per token,     6.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1641.93 ms /     4 runs   (  410.48 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =    3667.41 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    14 runs   (    0.25 ms per token,  3975.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2887.89 ms /    19 tokens (  151.99 ms per token,     6.58 tokens per second)\n",
      "llama_print_timings:        eval time =    5212.59 ms /    13 runs   (  400.97 ms per token,     2.49 tokens per second)\n",
      "llama_print_timings:       total time =    8133.34 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    11 runs   (    0.20 ms per token,  5018.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1973.80 ms /    13 tokens (  151.83 ms per token,     6.59 tokens per second)\n",
      "llama_print_timings:        eval time =    3992.69 ms /    10 runs   (  399.27 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    5987.01 ms /    23 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     5 runs   (    0.37 ms per token,  2708.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.35 ms /    10 tokens (  155.63 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1588.82 ms /     4 runs   (  397.20 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =    3159.70 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /    16 runs   (    0.23 ms per token,  4381.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3012.69 ms /    19 tokens (  158.56 ms per token,     6.31 tokens per second)\n",
      "llama_print_timings:        eval time =    5908.74 ms /    15 runs   (  393.92 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =    8957.67 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     8 runs   (    0.28 ms per token,  3519.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2404.66 ms /    15 tokens (  160.31 ms per token,     6.24 tokens per second)\n",
      "llama_print_timings:        eval time =    2756.42 ms /     7 runs   (  393.77 ms per token,     2.54 tokens per second)\n",
      "llama_print_timings:       total time =    5179.84 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     9 runs   (    0.22 ms per token,  4529.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2462.75 ms /    16 tokens (  153.92 ms per token,     6.50 tokens per second)\n",
      "llama_print_timings:        eval time =    3160.98 ms /     8 runs   (  395.12 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    5643.09 ms /    24 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    17 runs   (    0.22 ms per token,  4539.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3730.69 ms /    24 tokens (  155.45 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    6319.76 ms /    16 runs   (  394.98 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =   10085.31 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    19 runs   (    0.27 ms per token,  3684.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3863.83 ms /    24 tokens (  160.99 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:        eval time =    7106.43 ms /    18 runs   (  394.80 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =   11015.00 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     6 runs   (    0.29 ms per token,  3498.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2382.01 ms /    16 tokens (  148.88 ms per token,     6.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1979.03 ms /     5 runs   (  395.81 ms per token,     2.53 tokens per second)\n",
      "llama_print_timings:       total time =    4375.80 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    18 runs   (    0.23 ms per token,  4378.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4150.28 ms /    27 tokens (  153.71 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:        eval time =    6760.79 ms /    17 runs   (  397.69 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =   10948.80 ms /    44 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     8 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2904.19 ms /    19 tokens (  152.85 ms per token,     6.54 tokens per second)\n",
      "llama_print_timings:        eval time =    2796.66 ms /     7 runs   (  399.52 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    5719.33 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /     5 runs   (    0.29 ms per token,  3399.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1556.42 ms /    10 tokens (  155.64 ms per token,     6.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1640.13 ms /     4 runs   (  410.03 ms per token,     2.44 tokens per second)\n",
      "llama_print_timings:       total time =    3209.26 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     9 runs   (    0.19 ms per token,  5382.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1792.19 ms /    12 tokens (  149.35 ms per token,     6.70 tokens per second)\n",
      "llama_print_timings:        eval time =    3187.08 ms /     8 runs   (  398.38 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    4996.20 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     5 runs   (    0.36 ms per token,  2760.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2104.55 ms /    13 tokens (  161.89 ms per token,     6.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1669.86 ms /     4 runs   (  417.47 ms per token,     2.40 tokens per second)\n",
      "llama_print_timings:       total time =    3789.92 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     5 runs   (    0.31 ms per token,  3221.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1842.12 ms /    12 tokens (  153.51 ms per token,     6.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1600.97 ms /     4 runs   (  400.24 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    3456.49 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    10 runs   (    0.26 ms per token,  3818.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2809.66 ms /    18 tokens (  156.09 ms per token,     6.41 tokens per second)\n",
      "llama_print_timings:        eval time =    3586.21 ms /     9 runs   (  398.47 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    6419.47 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /    20 runs   (    0.18 ms per token,  5470.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4132.80 ms /    27 tokens (  153.07 ms per token,     6.53 tokens per second)\n",
      "llama_print_timings:        eval time =    7600.04 ms /    19 runs   (  400.00 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =   11770.98 ms /    46 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     5 runs   (    0.32 ms per token,  3162.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1933.37 ms /    12 tokens (  161.11 ms per token,     6.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.72 ms /     4 runs   (  400.43 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =    3548.55 ms /    16 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    29 runs   (    0.22 ms per token,  4478.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4830.47 ms /    32 tokens (  150.95 ms per token,     6.62 tokens per second)\n",
      "llama_print_timings:        eval time =   11217.88 ms /    28 runs   (  400.64 ms per token,     2.50 tokens per second)\n",
      "llama_print_timings:       total time =   16107.86 ms /    60 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =      10.03 ms /    42 runs   (    0.24 ms per token,  4185.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6215.89 ms /    40 tokens (  155.40 ms per token,     6.44 tokens per second)\n",
      "llama_print_timings:        eval time =   16238.34 ms /    41 runs   (  396.06 ms per token,     2.52 tokens per second)\n",
      "llama_print_timings:       total time =   22550.52 ms /    81 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     3 runs   (    0.29 ms per token,  3444.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1358.34 ms /     9 tokens (  150.93 ms per token,     6.63 tokens per second)\n",
      "llama_print_timings:        eval time =     705.56 ms /     2 runs   (  352.78 ms per token,     2.83 tokens per second)\n",
      "llama_print_timings:       total time =    2071.41 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     6 runs   (    0.24 ms per token,  4204.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2036.86 ms /    13 tokens (  156.68 ms per token,     6.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1773.54 ms /     5 runs   (  354.71 ms per token,     2.82 tokens per second)\n",
      "llama_print_timings:       total time =    3824.44 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /    16 runs   (    0.17 ms per token,  6058.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3758.79 ms /    26 tokens (  144.57 ms per token,     6.92 tokens per second)\n",
      "llama_print_timings:        eval time =    5202.90 ms /    15 runs   (  346.86 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    8988.94 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    12 runs   (    0.24 ms per token,  4179.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2505.19 ms /    17 tokens (  147.36 ms per token,     6.79 tokens per second)\n",
      "llama_print_timings:        eval time =    3832.18 ms /    11 runs   (  348.38 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    6361.29 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     8 runs   (    0.21 ms per token,  4742.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1965.93 ms /    13 tokens (  151.23 ms per token,     6.61 tokens per second)\n",
      "llama_print_timings:        eval time =    2447.29 ms /     7 runs   (  349.61 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    4428.70 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     6 runs   (    0.25 ms per token,  4067.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1336.84 ms /     9 tokens (  148.54 ms per token,     6.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1749.31 ms /     5 runs   (  349.86 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    3098.51 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     4 runs   (    0.19 ms per token,  5154.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1335.54 ms /     9 tokens (  148.39 ms per token,     6.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1054.63 ms /     3 runs   (  351.54 ms per token,     2.84 tokens per second)\n",
      "llama_print_timings:       total time =    2398.86 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    23 runs   (    0.18 ms per token,  5663.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2937.36 ms /    20 tokens (  146.87 ms per token,     6.81 tokens per second)\n",
      "llama_print_timings:        eval time =    7680.39 ms /    22 runs   (  349.11 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =   10658.06 ms /    42 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /     8 runs   (    0.19 ms per token,  5344.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1766.15 ms /    12 tokens (  147.18 ms per token,     6.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2476.12 ms /     7 runs   (  353.73 ms per token,     2.83 tokens per second)\n",
      "llama_print_timings:       total time =    4258.17 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     4 runs   (    0.19 ms per token,  5270.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.39 ms /     8 tokens (  148.80 ms per token,     6.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.55 ms /     3 runs   (  351.18 ms per token,     2.85 tokens per second)\n",
      "llama_print_timings:       total time =    2251.62 ms /    11 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    17 runs   (    0.21 ms per token,  4783.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3303.82 ms /    23 tokens (  143.64 ms per token,     6.96 tokens per second)\n",
      "llama_print_timings:        eval time =    5566.77 ms /    16 runs   (  347.92 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    8903.44 ms /    39 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    13 runs   (    0.23 ms per token,  4412.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2396.77 ms /    16 tokens (  149.80 ms per token,     6.68 tokens per second)\n",
      "llama_print_timings:        eval time =    4172.70 ms /    12 runs   (  347.73 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    6596.41 ms /    28 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5065.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1937.66 ms /    13 tokens (  149.05 ms per token,     6.71 tokens per second)\n",
      "llama_print_timings:        eval time =    2091.84 ms /     6 runs   (  348.64 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    4043.48 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     3 runs   (    0.31 ms per token,  3201.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.94 ms /     8 tokens (  148.99 ms per token,     6.71 tokens per second)\n",
      "llama_print_timings:        eval time =     703.79 ms /     2 runs   (  351.89 ms per token,     2.84 tokens per second)\n",
      "llama_print_timings:       total time =    1902.97 ms /    10 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    18 runs   (    0.17 ms per token,  5727.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3357.94 ms /    23 tokens (  146.00 ms per token,     6.85 tokens per second)\n",
      "llama_print_timings:        eval time =    5911.77 ms /    17 runs   (  347.75 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    9299.34 ms /    40 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    15 runs   (    0.24 ms per token,  4213.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2777.50 ms /    19 tokens (  146.18 ms per token,     6.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4860.28 ms /    14 runs   (  347.16 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    7666.87 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     9 runs   (    0.19 ms per token,  5260.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2059.70 ms /    14 tokens (  147.12 ms per token,     6.80 tokens per second)\n",
      "llama_print_timings:        eval time =    2785.72 ms /     8 runs   (  348.22 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    4862.68 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     8 runs   (    0.24 ms per token,  4132.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2261.29 ms /    15 tokens (  150.75 ms per token,     6.63 tokens per second)\n",
      "llama_print_timings:        eval time =    2441.56 ms /     7 runs   (  348.79 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    4719.21 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    13 runs   (    0.22 ms per token,  4613.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2200.91 ms /    15 tokens (  146.73 ms per token,     6.82 tokens per second)\n",
      "llama_print_timings:        eval time =    4161.62 ms /    12 runs   (  346.80 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    6387.66 ms /    27 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    14 runs   (    0.19 ms per token,  5293.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3072.33 ms /    21 tokens (  146.30 ms per token,     6.84 tokens per second)\n",
      "llama_print_timings:        eval time =    4505.86 ms /    13 runs   (  346.60 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =    7604.34 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /    12 runs   (    0.18 ms per token,  5647.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2931.50 ms /    20 tokens (  146.57 ms per token,     6.82 tokens per second)\n",
      "llama_print_timings:        eval time =    3831.31 ms /    11 runs   (  348.30 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    6783.48 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /    24 runs   (    0.17 ms per token,  6031.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3918.60 ms /    27 tokens (  145.13 ms per token,     6.89 tokens per second)\n",
      "llama_print_timings:        eval time =    7993.34 ms /    23 runs   (  347.54 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =   11950.60 ms /    50 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    15 runs   (    0.22 ms per token,  4639.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3203.13 ms /    22 tokens (  145.60 ms per token,     6.87 tokens per second)\n",
      "llama_print_timings:        eval time =    4921.75 ms /    14 runs   (  351.55 ms per token,     2.84 tokens per second)\n",
      "llama_print_timings:       total time =    8151.21 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /    10 runs   (    0.14 ms per token,  7256.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2360.30 ms /    16 tokens (  147.52 ms per token,     6.78 tokens per second)\n",
      "llama_print_timings:        eval time =    3118.01 ms /     9 runs   (  346.45 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =    5494.08 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     9 runs   (    0.24 ms per token,  4164.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2064.84 ms /    14 tokens (  147.49 ms per token,     6.78 tokens per second)\n",
      "llama_print_timings:        eval time =    2793.00 ms /     8 runs   (  349.12 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    4876.53 ms /    22 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /    19 runs   (    0.18 ms per token,  5408.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3352.65 ms /    23 tokens (  145.77 ms per token,     6.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6249.10 ms /    18 runs   (  347.17 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    9635.45 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /     8 runs   (    0.18 ms per token,  5483.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2057.12 ms /    14 tokens (  146.94 ms per token,     6.81 tokens per second)\n",
      "llama_print_timings:        eval time =    2436.03 ms /     7 runs   (  348.00 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    4509.34 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     7 runs   (    0.18 ms per token,  5524.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.17 ms /    13 tokens (  146.71 ms per token,     6.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2089.30 ms /     6 runs   (  348.22 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    4009.54 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    13 runs   (    0.16 ms per token,  6086.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3783.69 ms /    26 tokens (  145.53 ms per token,     6.87 tokens per second)\n",
      "llama_print_timings:        eval time =    4158.43 ms /    12 runs   (  346.54 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =    7965.08 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    13 runs   (    0.17 ms per token,  6004.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2849.30 ms /    19 tokens (  149.96 ms per token,     6.67 tokens per second)\n",
      "llama_print_timings:        eval time =    4192.54 ms /    12 runs   (  349.38 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    7064.38 ms /    31 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4422.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1913.99 ms /    13 tokens (  147.23 ms per token,     6.79 tokens per second)\n",
      "llama_print_timings:        eval time =    2466.27 ms /     7 runs   (  352.32 ms per token,     2.84 tokens per second)\n",
      "llama_print_timings:       total time =    4395.67 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /     6 runs   (    0.24 ms per token,  4166.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1476.94 ms /    10 tokens (  147.69 ms per token,     6.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1741.01 ms /     5 runs   (  348.20 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    3230.52 ms /    15 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    16 runs   (    0.24 ms per token,  4217.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3349.97 ms /    23 tokens (  145.65 ms per token,     6.87 tokens per second)\n",
      "llama_print_timings:        eval time =    5681.94 ms /    15 runs   (  378.80 ms per token,     2.64 tokens per second)\n",
      "llama_print_timings:       total time =    9066.61 ms /    38 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     4 runs   (    0.24 ms per token,  4175.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1354.41 ms /     9 tokens (  150.49 ms per token,     6.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.24 ms /     3 runs   (  399.08 ms per token,     2.51 tokens per second)\n",
      "llama_print_timings:       total time =    2562.87 ms /    12 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /    17 runs   (    0.21 ms per token,  4821.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3146.22 ms /    21 tokens (  149.82 ms per token,     6.67 tokens per second)\n",
      "llama_print_timings:        eval time =    5601.97 ms /    16 runs   (  350.12 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    8779.98 ms /    37 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     6 runs   (    0.22 ms per token,  4559.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1761.70 ms /    12 tokens (  146.81 ms per token,     6.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1747.79 ms /     5 runs   (  349.56 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    3521.22 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    14 runs   (    0.17 ms per token,  6026.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3349.18 ms /    23 tokens (  145.62 ms per token,     6.87 tokens per second)\n",
      "llama_print_timings:        eval time =    4512.94 ms /    13 runs   (  347.15 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    7887.28 ms /    36 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     7 runs   (    0.31 ms per token,  3257.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1893.35 ms /    13 tokens (  145.64 ms per token,     6.87 tokens per second)\n",
      "llama_print_timings:        eval time =    2087.64 ms /     6 runs   (  347.94 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    3999.24 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     9 runs   (    0.24 ms per token,  4118.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.86 ms /    11 tokens (  145.44 ms per token,     6.88 tokens per second)\n",
      "llama_print_timings:        eval time =    2766.13 ms /     8 runs   (  345.77 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =    4385.70 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    18 runs   (    0.17 ms per token,  5863.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2628.78 ms /    18 tokens (  146.04 ms per token,     6.85 tokens per second)\n",
      "llama_print_timings:        eval time =    5875.54 ms /    17 runs   (  345.62 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =    8534.12 ms /    35 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     6 runs   (    0.24 ms per token,  4143.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1316.93 ms /     9 tokens (  146.33 ms per token,     6.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1732.06 ms /     5 runs   (  346.41 ms per token,     2.89 tokens per second)\n",
      "llama_print_timings:       total time =    3061.30 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    10 runs   (    0.22 ms per token,  4633.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2467.28 ms /    17 tokens (  145.13 ms per token,     6.89 tokens per second)\n",
      "llama_print_timings:        eval time =    3133.49 ms /     9 runs   (  348.17 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    5619.73 ms /    26 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     6 runs   (    0.23 ms per token,  4335.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1339.80 ms /     9 tokens (  148.87 ms per token,     6.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1739.47 ms /     5 runs   (  347.89 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    3090.58 ms /    14 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  5010.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1634.19 ms /    11 tokens (  148.56 ms per token,     6.73 tokens per second)\n",
      "llama_print_timings:        eval time =    2081.85 ms /     6 runs   (  346.97 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    3729.39 ms /    17 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     6 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2200.18 ms /    15 tokens (  146.68 ms per token,     6.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1740.95 ms /     5 runs   (  348.19 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    3951.29 ms /    20 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    12 runs   (    0.22 ms per token,  4649.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3292.32 ms /    22 tokens (  149.65 ms per token,     6.68 tokens per second)\n",
      "llama_print_timings:        eval time =    3817.98 ms /    11 runs   (  347.09 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    7133.54 ms /    33 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4691.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1905.71 ms /    13 tokens (  146.59 ms per token,     6.82 tokens per second)\n",
      "llama_print_timings:        eval time =    2092.75 ms /     6 runs   (  348.79 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =    4012.63 ms /    19 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.87 ms /    32 runs   (    0.18 ms per token,  5455.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    6814.77 ms /    46 tokens (  148.15 ms per token,     6.75 tokens per second)\n",
      "llama_print_timings:        eval time =   11223.50 ms /    31 runs   (  362.05 ms per token,     2.76 tokens per second)\n",
      "llama_print_timings:       total time =   18096.17 ms /    77 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    25 runs   (    0.19 ms per token,  5205.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4279.37 ms /    29 tokens (  147.56 ms per token,     6.78 tokens per second)\n",
      "llama_print_timings:        eval time =    8350.38 ms /    24 runs   (  347.93 ms per token,     2.87 tokens per second)\n",
      "llama_print_timings:       total time =   12676.24 ms /    53 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    32 runs   (    0.18 ms per token,  5485.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    4997.28 ms /    34 tokens (  146.98 ms per token,     6.80 tokens per second)\n",
      "llama_print_timings:        eval time =   10747.25 ms /    31 runs   (  346.69 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =   15803.30 ms /    65 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /    20 runs   (    0.18 ms per token,  5549.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3205.52 ms /    22 tokens (  145.71 ms per token,     6.86 tokens per second)\n",
      "llama_print_timings:        eval time =    6608.17 ms /    19 runs   (  347.80 ms per token,     2.88 tokens per second)\n",
      "llama_print_timings:       total time =    9849.66 ms /    41 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     7 runs   (    0.19 ms per token,  5173.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2215.79 ms /    15 tokens (  147.72 ms per token,     6.77 tokens per second)\n",
      "llama_print_timings:        eval time =    2098.73 ms /     6 runs   (  349.79 ms per token,     2.86 tokens per second)\n",
      "llama_print_timings:       total time =    4327.24 ms /    21 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /    12 runs   (    0.17 ms per token,  5994.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3063.73 ms /    21 tokens (  145.89 ms per token,     6.85 tokens per second)\n",
      "llama_print_timings:        eval time =    3892.67 ms /    11 runs   (  353.88 ms per token,     2.83 tokens per second)\n",
      "llama_print_timings:       total time =    6976.76 ms /    32 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /    11 runs   (    0.26 ms per token,  3774.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2672.88 ms /    15 tokens (  178.19 ms per token,     5.61 tokens per second)\n",
      "llama_print_timings:        eval time =    4193.58 ms /    10 runs   (  419.36 ms per token,     2.38 tokens per second)\n",
      "llama_print_timings:       total time =    6892.33 ms /    25 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     6 runs   (    0.28 ms per token,  3554.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2204.98 ms /    13 tokens (  169.61 ms per token,     5.90 tokens per second)\n",
      "llama_print_timings:        eval time =    2014.62 ms /     5 runs   (  402.92 ms per token,     2.48 tokens per second)\n",
      "llama_print_timings:       total time =    4233.58 ms /    18 tokens\n",
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   10962.98 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    12 runs   (    0.23 ms per token,  4256.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3554.13 ms /    23 tokens (  154.53 ms per token,     6.47 tokens per second)\n",
      "llama_print_timings:        eval time =    4587.00 ms /    11 runs   (  417.00 ms per token,     2.40 tokens per second)\n",
      "llama_print_timings:       total time =    8166.98 ms /    34 tokens\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "goblin_df['trg_sent']=goblin_df['src_sent'].apply(lambda txt: ko2en.get_translation(txt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode</th>\n",
       "      <th>text</th>\n",
       "      <th>src_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...</td>\n",
       "      <td>숱한 전장에서 수천의 피를 묻힌 검이 제 주인의 피까지 묻혔으니 오죽 했을까?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...</td>\n",
       "      <td>오직 도깨비 신부만이 그 검을 뽑을 것이다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...</td>\n",
       "      <td>검을 뽑으면 무(아무것도 아닌 것;Nothing/Zero)로 돌아가 평안 하리라.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>도깨비 Episode_1.docx</td>\n",
       "      <td>Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...</td>\n",
       "      <td>고약한 신탁이 아닐 수 없었지.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도깨비 Episode_9.docx</td>\n",
       "      <td>도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...</td>\n",
       "      <td>김써니씨 라고 했는데.. 아 많이 추우시죠?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도깨비 Episode_9.docx</td>\n",
       "      <td>도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...</td>\n",
       "      <td>제가 금방 코트..\\n\\n 내 얘기 아직 안 끝났어요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도깨비 Episode_9.docx</td>\n",
       "      <td>도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...</td>\n",
       "      <td>무언가 잘못 되었어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도깨비 Episode_9.docx</td>\n",
       "      <td>도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...</td>\n",
       "      <td>아마 당신부터인 것 같은데..\\n\\n \\n\\n (왜 그래요?)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>도깨비 Episode_9.docx</td>\n",
       "      <td>도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...</td>\n",
       "      <td>대체.. 왜..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11483 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  episode                                               text  \\\n",
       "0   도깨비 Episode_1.docx   Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...   \n",
       "0   도깨비 Episode_1.docx   Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...   \n",
       "0   도깨비 Episode_1.docx   Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...   \n",
       "0   도깨비 Episode_1.docx   Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...   \n",
       "0   도깨비 Episode_1.docx   Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼...   \n",
       "..                    ...                                                ...   \n",
       "15  도깨비 Episode_9.docx   도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...   \n",
       "15  도깨비 Episode_9.docx   도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...   \n",
       "15  도깨비 Episode_9.docx   도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...   \n",
       "15  도깨비 Episode_9.docx   도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...   \n",
       "15  도깨비 Episode_9.docx   도깨비 Episode_9\\n\\n \\n\\n 그러니까 그 검을 빼면 아저씨가 없어진다...   \n",
       "\n",
       "                                             src_sent  \n",
       "0   Episode_1\\n\\n \\n\\n ★\\n\\n 사람의 손때나 피가 묻은 물건에 영혼이...  \n",
       "0         숱한 전장에서 수천의 피를 묻힌 검이 제 주인의 피까지 묻혔으니 오죽 했을까?  \n",
       "0                            오직 도깨비 신부만이 그 검을 뽑을 것이다.  \n",
       "0       검을 뽑으면 무(아무것도 아닌 것;Nothing/Zero)로 돌아가 평안 하리라.  \n",
       "0                                   고약한 신탁이 아닐 수 없었지.  \n",
       "..                                                ...  \n",
       "15                           김써니씨 라고 했는데.. 아 많이 추우시죠?  \n",
       "15                     제가 금방 코트..\\n\\n 내 얘기 아직 안 끝났어요.  \n",
       "15                                        무언가 잘못 되었어.  \n",
       "15                 아마 당신부터인 것 같은데..\\n\\n \\n\\n (왜 그래요?)  \n",
       "15                                           대체.. 왜..  \n",
       "\n",
       "[11483 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "goblin_df['rev_src_sent']=goblin_df['trg_sent'].apply(lambda txt: ko2en.get_translation(txt))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
